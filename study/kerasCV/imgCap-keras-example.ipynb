{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2695b173-1b94-4466-a326-4f36f4ac7f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGES_PATH = \"/media/loveplay1983/data/ML/imgcap/Flickr/flickr8k/Flicker8k_Dataset\" \n",
    "# captions_mapping, text_data = load_captions_data(\"/media/loveplay1983/data/ML/imgcap/Flickr/flickr8k/Flickr8k_text/Flickr8k.token.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cccab119-b31e-444a-8015-f08566498f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 15:11:27.063905: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-15 15:11:28.084894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.applications import efficientnet\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "\n",
    "keras.utils.set_random_seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b772f2ee-1780-433c-9990-3f237f961db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n",
      "Current tensorflow -> 2.16.1\n",
      "Current keras -> 3.1.1\n"
     ]
    }
   ],
   "source": [
    "# Test keras version and cuda installation\n",
    "for each in tf.config.list_physical_devices():\n",
    "    print(each)\n",
    "    \n",
    "print(\"Current tensorflow ->\", tf.__version__)\n",
    "print(\"Current keras ->\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d180411b-a5e8-46af-8f3c-22db15da5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# K.clear_session()\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d344191a-f23c-4146-80b2-a49304375ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Get a list of physical devices (GPUs)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c1fe54-20d6-4b94-86c0-5dfc90791e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the GPU to use (adjust the index as needed)\n",
    "def switch_device(device_index: int):\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[device_index], 'GPU')\n",
    "        logical_gpus = tf.config.list_physical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        print(f\"current device -> {gpus[0]}\")\n",
    "    except RuntimeError as e:\n",
    "        # Log error\n",
    "        print(e)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589557c4-d02a-4195-b7f2-1375b30f9250",
   "metadata": {},
   "source": [
    "Both `tf.config.set_visible_devices` and `tf.device` are used in TensorFlow to manage GPU resources, but they serve different purposes:\n",
    "\n",
    "**1. `tf.config.set_visible_devices`:**\n",
    "\n",
    "* **Function:** Sets the overall visibility of GPUs to TensorFlow.\n",
    "* **Scope:** Affects all TensorFlow operations within the current Python session.\n",
    "* **Usage:** Useful for controlling which GPUs are available for TensorFlow to use in a broader sense.\n",
    "* **Example:**\n",
    "  ```python\n",
    "  gpus = tf.config.list_physical_devices('GPU')\n",
    "  tf.config.set_visible_devices(gpus[1], 'GPU')  # Make only the second GPU visible\n",
    "  ```\n",
    "\n",
    "**2. `tf.device`:**\n",
    "\n",
    "* **Function:** Sets the device (CPU or specific GPU) where a specific operation or block of code is executed.\n",
    "* **Scope:** Applies only to the operations within the `with tf.device` context.\n",
    "* **Usage:** Useful for fine-grained control over where specific computations are performed.\n",
    "* **Example:**\n",
    "  ```python\n",
    "  with tf.device('/gpu:0'):\n",
    "    # Operations placed here will run on the first GPU\n",
    "    ...\n",
    "  with tf.device('/cpu:0'):\n",
    "    # Operations here will run on the CPU\n",
    "    ...\n",
    "  ```\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "| Feature        | `tf.config.set_visible_devices` | `tf.device` |\n",
    "|----------------|-------------------------------|--------------|\n",
    "| Scope           | Global for the entire session   | Local for a specific code block |\n",
    "| Control        | Visibility of GPUs               | Execution device for operations |\n",
    "| Use case        | Select GPUs for TensorFlow      | Assign operations to specific devices |\n",
    "\n",
    "**In Summary:**\n",
    "\n",
    "* Use `tf.config.set_visible_devices` to control which GPUs are available for TensorFlow overall.\n",
    "* Use `tf.device` to control the specific device (CPU or GPU) where individual operations or code blocks are executed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7bda9d-0a7d-44a9-be12-960f87c7d5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78a807-f9fa-4d6c-a19b-0dbbae9e84fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38db4b15-a8c2-44ff-979e-1e28af642c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n",
      "current device -> PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# use device 0\n",
    "switch_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8329e5-3bfb-43a1-a192-151dadebb975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the images\n",
    "IMAGES_PATH = \"/media/loveplay1983/data/ML/imgcap/Flickr/flickr8k/Flicker8k_Dataset\" \n",
    "\n",
    "# Desired image dimensions\n",
    "IMAGE_SIZE = (299, 299)\n",
    "\n",
    "# Vocabulary size\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "# Fixed length allowed for any sequence\n",
    "SEQ_LENGTH = 25\n",
    "\n",
    "# Dimension for the image embeddings and token embeddings\n",
    "EMBED_DIM = 512\n",
    "\n",
    "# Per-layer units in the feed-forward network\n",
    "FF_DIM = 512\n",
    "\n",
    "# Other training parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c13109aa-05dc-469d-8e2a-c7d136769729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_captions_data(filename):\n",
    "    \"\"\"Loads captions (text) data and maps them to corresponding images.\n",
    "    Args:\n",
    "        filename: Path to the text file containing caption data.\n",
    "\n",
    "    Returns:\n",
    "        caption_mapping: Dictionary mapping image names and the corresponding captions\n",
    "        text_data: List containing all the available captions\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename) as caption_file:\n",
    "        caption_data = caption_file.readlines()\n",
    "        caption_mapping = {}\n",
    "        text_data = []\n",
    "        images_to_skip = set()\n",
    "\n",
    "        for line in caption_data:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            # Image name and captions are separated using a tab\n",
    "            img_name, caption = line.split(\"\\t\")\n",
    "\n",
    "            # Each image is repeated five times for the five different captions.\n",
    "            # Each image name has a suffix `#(caption_number)`\n",
    "            img_name = img_name.split(\"#\")[0]\n",
    "            img_name = os.path.join(IMAGES_PATH, img_name.strip())\n",
    "\n",
    "            # We will remove caption that are either too short to too long\n",
    "            tokens = caption.strip().split()\n",
    "\n",
    "            if len(tokens) < 5 or len(tokens) > SEQ_LENGTH:\n",
    "                images_to_skip.add(img_name)\n",
    "                continue\n",
    "\n",
    "            if img_name.endswith(\"jpg\") and img_name not in images_to_skip:\n",
    "                # We will add a start and an end token to each caption\n",
    "                caption = \"<start> \" + caption.strip() + \" <end>\"\n",
    "                text_data.append(caption)\n",
    "\n",
    "                if img_name in caption_mapping:\n",
    "                    caption_mapping[img_name].append(caption)\n",
    "                else:\n",
    "                    caption_mapping[img_name] = [caption]\n",
    "\n",
    "        for img_name in images_to_skip:\n",
    "            if img_name in caption_mapping:\n",
    "                del caption_mapping[img_name]\n",
    "\n",
    "        return caption_mapping, text_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d3cacc-c37a-47a9-a989-f164ef096760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_split(caption_data, train_size=0.8, shuffle=True):\n",
    "    \"\"\"Split the captioning dataset into train and validation sets.\n",
    "\n",
    "    Args:\n",
    "        caption_data (dict): Dictionary containing the mapped caption data\n",
    "        train_size (float): Fraction of all the full dataset to use as training data\n",
    "        shuffle (bool): Whether to shuffle the dataset before splitting\n",
    "\n",
    "    Returns:\n",
    "        Traning and validation datasets as two separated dicts\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Get the list of all image names\n",
    "    all_images = list(caption_data.keys())\n",
    "\n",
    "    # 2. Shuffle if necessary\n",
    "    if shuffle:\n",
    "        np.random.shuffle(all_images)\n",
    "\n",
    "    # 3. Split into training and validation sets\n",
    "    train_size = int(len(caption_data) * train_size)\n",
    "\n",
    "    training_data = {\n",
    "        img_name: caption_data[img_name] for img_name in all_images[:train_size]\n",
    "    }\n",
    "    validation_data = {\n",
    "        img_name: caption_data[img_name] for img_name in all_images[train_size:]\n",
    "    }\n",
    "\n",
    "    # 4. Return the splits\n",
    "    return training_data, validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74776f37-02c0-4ade-ab88-d2b145c874da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  6114\n",
      "Number of validation samples:  1529\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "captions_mapping, text_data = load_captions_data(\"/media/loveplay1983/data/ML/imgcap/Flickr/flickr8k/Flickr8k_text/Flickr8k.token.txt\")\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data, valid_data = train_val_split(captions_mapping)\n",
    "print(\"Number of training samples: \", len(train_data))\n",
    "print(\"Number of validation samples: \", len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b1a1dc4-be28-45a4-a18e-3974dc1a9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf94a9b-54e3-4425-ba8a-636193be99a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "strip_chars = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "strip_chars = strip_chars.replace(\"<\", \"\")\n",
    "strip_chars = strip_chars.replace(\">\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e014ed-fdb0-49f4-9708-4eecd367eeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 15:11:37.103402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22446 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "vectorization = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQ_LENGTH,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "vectorization.adapt(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f5be09b-7df4-431f-a15f-44ec3013720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for image data\n",
    "image_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.2),\n",
    "        layers.RandomContrast(0.3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb69f2c8-4139-4c28-9ab4-96d86d8045d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visible devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "# use device 0\n",
    "switch_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc8413-756f-4c0d-a228-078941556f00",
   "metadata": {},
   "source": [
    "`\n",
    "## Building a `tf.data.Dataset` pipeline for training\n",
    "\n",
    "We will generate pairs of images and corresponding captions using a `tf.data.Dataset` object.\n",
    "The pipeline consists of two steps:\n",
    "\n",
    "1. Read the image from the disk\n",
    "2. Tokenize all the five captions corresponding to the image\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea60133e-7c8c-454a-9548-f36096a9dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_and_resize(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMAGE_SIZE)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "134f3d08-6a7d-48a4-968d-9a63ea0acffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(img_path, captions):\n",
    "    return decode_and_resize(img_path), vectorization(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "045fb841-38c0-43c7-be05-48c915ebcd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(images, captions):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, captions))\n",
    "    dataset = dataset.shuffle(BATCH_SIZE * 8)\n",
    "    dataset = dataset.map(process_input, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e28fd270-75ca-475f-be2b-577fea8d26fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the list of images and the list of corresponding captions\n",
    "train_dataset = make_dataset(list(train_data.keys()), list(train_data.values()))\n",
    "\n",
    "valid_dataset = make_dataset(list(valid_data.keys()), list(valid_data.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70861d5f-85e5-460b-9573-330b82692066",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Our image captioning architecture consists of three models:\n",
    "\n",
    "1. A CNN: used to extract the image features\n",
    "2. A TransformerEncoder: The extracted image features are then passed to a Transformer\n",
    "                    based encoder that generates a new representation of the inputs\n",
    "3. A TransformerDecoder: This model takes the encoder output and the text data\n",
    "                    (sequences) as inputs and tries to learn to generate the caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a128883c-fbd7-4285-bb86-68e800a36a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    base_model = efficientnet.EfficientNetB0(\n",
    "        input_shape=(*IMAGE_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "    )\n",
    "    # We freeze our feature extractor\n",
    "    base_model.trainable = False\n",
    "    base_model_out = base_model.output\n",
    "    base_model_out = layers.Reshape((-1, base_model_out.shape[-1]))(base_model_out)\n",
    "    cnn_model = keras.models.Model(base_model.input, base_model_out)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8831fbc-45a3-4ef3-b9c6-2ee0edfe0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.0\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.dense_1 = layers.Dense(embed_dim, activation=\"relu\")\n",
    "\n",
    "    def call(self, inputs, training, mask=None):\n",
    "        inputs = self.layernorm_1(inputs)\n",
    "        inputs = self.dense_1(inputs)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=None,\n",
    "            training=training,\n",
    "        )\n",
    "        out_1 = self.layernorm_2(inputs + attention_output_1)\n",
    "        return out_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "072a6ff7-4c6b-4901-b914-06a105c1df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embed_scale = tf.math.sqrt(tf.cast(embed_dim, tf.float32))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_tokens = embedded_tokens * self.embed_scale\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee8b9ae0-62a7-43e5-a04b-b7d094c46185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, ff_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n",
    "        )\n",
    "        self.ffn_layer_1 = layers.Dense(ff_dim, activation=\"relu\")\n",
    "        self.ffn_layer_2 = layers.Dense(embed_dim)\n",
    "\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "\n",
    "        self.embedding = PositionalEmbedding(\n",
    "            embed_dim=EMBED_DIM,\n",
    "            sequence_length=SEQ_LENGTH,\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "        )\n",
    "        self.out = layers.Dense(VOCAB_SIZE, activation=\"softmax\")\n",
    "\n",
    "        self.dropout_1 = layers.Dropout(0.3)\n",
    "        self.dropout_2 = layers.Dropout(0.5)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, training, mask=None):\n",
    "        inputs = self.embedding(inputs)\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, :, tf.newaxis], dtype=tf.int32)\n",
    "            combined_mask = tf.cast(mask[:, tf.newaxis, :], dtype=tf.int32)\n",
    "            combined_mask = tf.minimum(combined_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=combined_mask,\n",
    "            training=training,\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "            training=training,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        ffn_out = self.ffn_layer_1(out_2)\n",
    "        ffn_out = self.dropout_1(ffn_out, training=training)\n",
    "        ffn_out = self.ffn_layer_2(ffn_out)\n",
    "\n",
    "        ffn_out = self.layernorm_3(ffn_out + out_2, training=training)\n",
    "        ffn_out = self.dropout_2(ffn_out, training=training)\n",
    "        preds = self.out(ffn_out)\n",
    "        return preds\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [\n",
    "                tf.expand_dims(batch_size, -1),\n",
    "                tf.constant([1, 1], dtype=tf.int32),\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e35b38b8-d77b-497d-b2dd-641868591e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCaptioningModel(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cnn_model,\n",
    "        encoder,\n",
    "        decoder,\n",
    "        num_captions_per_image=5,\n",
    "        image_aug=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.acc_tracker = keras.metrics.Mean(name=\"accuracy\")\n",
    "        self.num_captions_per_image = num_captions_per_image\n",
    "        self.image_aug = image_aug\n",
    "\n",
    "    def calculate_loss(self, y_true, y_pred, mask):\n",
    "        loss = self.loss(y_true, y_pred)\n",
    "        mask = tf.cast(mask, dtype=loss.dtype)\n",
    "        loss *= mask\n",
    "        return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "    def calculate_accuracy(self, y_true, y_pred, mask):\n",
    "        accuracy = tf.equal(y_true, tf.argmax(y_pred, axis=2))\n",
    "        accuracy = tf.math.logical_and(mask, accuracy)\n",
    "        accuracy = tf.cast(accuracy, dtype=tf.float32)\n",
    "        mask = tf.cast(mask, dtype=tf.float32)\n",
    "        return tf.reduce_sum(accuracy) / tf.reduce_sum(mask)\n",
    "\n",
    "    def _compute_caption_loss_and_acc(self, img_embed, batch_seq, training=True):\n",
    "        encoder_out = self.encoder(img_embed, training=training)\n",
    "        batch_seq_inp = batch_seq[:, :-1]\n",
    "        batch_seq_true = batch_seq[:, 1:]\n",
    "        mask = tf.math.not_equal(batch_seq_true, 0)\n",
    "        batch_seq_pred = self.decoder(\n",
    "            batch_seq_inp, encoder_out, training=training, mask=mask\n",
    "        )\n",
    "        loss = self.calculate_loss(batch_seq_true, batch_seq_pred, mask)\n",
    "        acc = self.calculate_accuracy(batch_seq_true, batch_seq_pred, mask)\n",
    "        return loss, acc\n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "        batch_img, batch_seq = batch_data\n",
    "        batch_loss = 0\n",
    "        batch_acc = 0\n",
    "\n",
    "        if self.image_aug:\n",
    "            batch_img = self.image_aug(batch_img)\n",
    "\n",
    "        # 1. Get image embeddings\n",
    "        img_embed = self.cnn_model(batch_img)\n",
    "\n",
    "        # 2. Pass each of the five captions one by one to the decoder\n",
    "        # along with the encoder outputs and compute the loss as well as accuracy\n",
    "        # for each caption.\n",
    "        for i in range(self.num_captions_per_image):\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss, acc = self._compute_caption_loss_and_acc(\n",
    "                    img_embed, batch_seq[:, i, :], training=True\n",
    "                )\n",
    "\n",
    "                # 3. Update loss and accuracy\n",
    "                batch_loss += loss\n",
    "                batch_acc += acc\n",
    "\n",
    "            # 4. Get the list of all the trainable weights\n",
    "            train_vars = (\n",
    "                self.encoder.trainable_variables + self.decoder.trainable_variables\n",
    "            )\n",
    "\n",
    "            # 5. Get the gradients\n",
    "            grads = tape.gradient(loss, train_vars)\n",
    "\n",
    "            # 6. Update the trainable weights\n",
    "            self.optimizer.apply_gradients(zip(grads, train_vars))\n",
    "\n",
    "        # 7. Update the trackers\n",
    "        batch_acc /= float(self.num_captions_per_image)\n",
    "        self.loss_tracker.update_state(batch_loss)\n",
    "        self.acc_tracker.update_state(batch_acc)\n",
    "\n",
    "        # 8. Return the loss and accuracy values\n",
    "        return {\n",
    "            \"loss\": self.loss_tracker.result(),\n",
    "            \"acc\": self.acc_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, batch_data):\n",
    "        batch_img, batch_seq = batch_data\n",
    "        batch_loss = 0\n",
    "        batch_acc = 0\n",
    "\n",
    "        # 1. Get image embeddings\n",
    "        img_embed = self.cnn_model(batch_img)\n",
    "\n",
    "        # 2. Pass each of the five captions one by one to the decoder\n",
    "        # along with the encoder outputs and compute the loss as well as accuracy\n",
    "        # for each caption.\n",
    "        for i in range(self.num_captions_per_image):\n",
    "            loss, acc = self._compute_caption_loss_and_acc(\n",
    "                img_embed, batch_seq[:, i, :], training=False\n",
    "            )\n",
    "\n",
    "            # 3. Update batch loss and batch accuracy\n",
    "            batch_loss += loss\n",
    "            batch_acc += acc\n",
    "\n",
    "        batch_acc /= float(self.num_captions_per_image)\n",
    "\n",
    "        # 4. Update the trackers\n",
    "        self.loss_tracker.update_state(batch_loss)\n",
    "        self.acc_tracker.update_state(batch_acc)\n",
    "\n",
    "        # 5. Return the loss and accuracy values\n",
    "        return {\n",
    "            \"loss\": self.loss_tracker.result(),\n",
    "            \"acc\": self.acc_tracker.result(),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker, self.acc_tracker]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f8d8f46-fe82-4ff4-b426-97f7e46fedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = get_cnn_model()\n",
    "encoder = TransformerEncoderBlock(embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=1)\n",
    "decoder = TransformerDecoderBlock(embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=2)\n",
    "caption_model = ImageCaptioningModel(\n",
    "    cnn_model=cnn_model,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    image_aug=image_augmentation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72671591-83d8-476d-9f51-e431d393aa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"image_captioning_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"image_captioning_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ functional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_block       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_decoder_block       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ functional_1 (\u001b[38;5;33mFunctional\u001b[0m)       │ ?                      │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_block       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_decoder_block       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "caption_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1b00905-0813-4551-8e8d-0b2b63e33f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    reduction=None,\n",
    ")\n",
    "\n",
    "# EarlyStopping criteria\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55d32247-7b32-46dd-8999-05342a1ab8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler for the optimizer\n",
    "class LRSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, post_warmup_learning_rate, warmup_steps):\n",
    "        super().__init__()\n",
    "        self.post_warmup_learning_rate = post_warmup_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        global_step = tf.cast(step, tf.float32)\n",
    "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
    "        warmup_progress = global_step / warmup_steps\n",
    "        warmup_learning_rate = self.post_warmup_learning_rate * warmup_progress\n",
    "        return tf.cond(\n",
    "            global_step < warmup_steps,\n",
    "            lambda: warmup_learning_rate,\n",
    "            lambda: self.post_warmup_learning_rate,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37deb6f3-4d15-4501-8b06-3c58ee8e2e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a learning rate schedule\n",
    "num_train_steps = len(train_dataset) * EPOCHS\n",
    "num_warmup_steps = num_train_steps // 15\n",
    "lr_schedule = LRSchedule(post_warmup_learning_rate=1e-4, warmup_steps=num_warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1065fc6-1789-420d-b1cf-aa744add53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "caption_model.compile(optimizer=keras.optimizers.Adam(lr_schedule), \n",
    "                      loss=cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be167a-da0a-4b1c-baed-070a9d60f5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fa2b1-9c0d-4591-97d1-ddb67ef8ceef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa62f4ca-5f49-41c5-9d8a-aa3946e019f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loveplay1983/Workstation/Anaconda/anaconda/envs/keras3test/lib/python3.12/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/loveplay1983/Workstation/Anaconda/anaconda/envs/keras3test/lib/python3.12/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/loveplay1983/Workstation/Anaconda/anaconda/envs/keras3test/lib/python3.12/site-packages/keras/src/layers/layer.py:845: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "2024-07-15 15:12:38.044782: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 251ms/step - acc: 0.1588 - loss: 32.9298 - accuracy: 0.2394 - val_accuracy: 0.3011 - val_loss: 19.3170\n",
      "Epoch 2/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - acc: 0.3337 - loss: 18.8807 - accuracy: 0.3446 - val_accuracy: 0.3603 - val_loss: 17.2637\n",
      "Epoch 3/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - acc: 0.3650 - loss: 16.9423 - accuracy: 0.3701 - val_accuracy: 0.3749 - val_loss: 16.4301\n",
      "Epoch 4/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 164ms/step - acc: 0.3829 - loss: 15.8662 - accuracy: 0.3877 - val_accuracy: 0.3893 - val_loss: 15.8455\n",
      "Epoch 5/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - acc: 0.3959 - loss: 15.0999 - accuracy: 0.4015 - val_accuracy: 0.3962 - val_loss: 15.5813\n",
      "Epoch 6/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 164ms/step - acc: 0.4114 - loss: 14.4099 - accuracy: 0.4150 - val_accuracy: 0.4031 - val_loss: 15.3569\n",
      "Epoch 7/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 164ms/step - acc: 0.4197 - loss: 13.9175 - accuracy: 0.4243 - val_accuracy: 0.4058 - val_loss: 15.1743\n",
      "Epoch 8/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 165ms/step - acc: 0.4314 - loss: 13.4089 - accuracy: 0.4347 - val_accuracy: 0.4100 - val_loss: 15.1452\n",
      "Epoch 9/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 165ms/step - acc: 0.4416 - loss: 12.9946 - accuracy: 0.4440 - val_accuracy: 0.4113 - val_loss: 15.0742\n",
      "Epoch 10/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 165ms/step - acc: 0.4492 - loss: 12.5923 - accuracy: 0.4531 - val_accuracy: 0.4107 - val_loss: 15.1153\n",
      "Epoch 11/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 165ms/step - acc: 0.4567 - loss: 12.2750 - accuracy: 0.4603 - val_accuracy: 0.4080 - val_loss: 15.1411\n",
      "Epoch 12/30\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 165ms/step - acc: 0.4646 - loss: 11.9568 - accuracy: 0.4687 - val_accuracy: 0.4077 - val_loss: 15.1374\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "with tf.device(\"gpu:1\"):\n",
    "    hist = caption_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=valid_dataset,\n",
    "        callbacks=[early_stopping],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0f7cd7a-bb1a-4ca3-be15-73aa754d20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(item):\n",
    "    plt.plot(hist.history[item], label=item)\n",
    "    plt.plot(hist.history[\"val_\"+item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34cc46e0-7875-4e28-a341-d19a57b56122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c7c02-934c-4ace-8fe6-624e6717793b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb3a6e-0f51-47fa-b692-4bcd66e0395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorization.get_vocabulary()\n",
    "index_lookup = dict(zip(range(len(vocab)), vocab))\n",
    "max_decoded_sentence_length = SEQ_LENGTH - 1\n",
    "valid_images = list(valid_data.keys())\n",
    "\n",
    "\n",
    "def generate_caption():\n",
    "    # Select a random image from the validation dataset\n",
    "    sample_img = np.random.choice(valid_images)\n",
    "\n",
    "    # Read the image from the disk\n",
    "    sample_img = decode_and_resize(sample_img)\n",
    "    img = sample_img.numpy().clip(0, 255).astype(np.uint8)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    # Pass the image to the CNN\n",
    "    img = tf.expand_dims(sample_img, 0)\n",
    "    img = caption_model.cnn_model(img)\n",
    "\n",
    "    # Pass the image features to the Transformer encoder\n",
    "    encoded_img = caption_model.encoder(img, training=False)\n",
    "\n",
    "    # Generate the caption using the Transformer decoder\n",
    "    decoded_caption = \"<start> \"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_caption = vectorization([decoded_caption])[:, :-1]\n",
    "        mask = tf.math.not_equal(tokenized_caption, 0)\n",
    "        predictions = caption_model.decoder(\n",
    "            tokenized_caption, encoded_img, training=False, mask=mask\n",
    "        )\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = index_lookup[sampled_token_index]\n",
    "        if sampled_token == \"<end>\":\n",
    "            break\n",
    "        decoded_caption += \" \" + sampled_token\n",
    "\n",
    "    decoded_caption = decoded_caption.replace(\"<start> \", \"\")\n",
    "    decoded_caption = decoded_caption.replace(\" <end>\", \"\").strip()\n",
    "    print(\"Predicted Caption: \", decoded_caption)\n",
    "\n",
    "\n",
    "# Check predictions for a few samples\n",
    "generate_caption()\n",
    "generate_caption()\n",
    "generate_caption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c6c6a-4af5-43a4-9925-b3bcbc885817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c375a-e0eb-44a5-b914-bb26b19a9c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras3",
   "language": "python",
   "name": "keras3test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
